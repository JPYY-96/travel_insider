{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from google.cloud import bigquery\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from pycaret.regression import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ [2025-03-13 20:15:44] Loading data from BigQuery in chunks...\n",
      "✅ [2025-03-13 20:15:56] Loaded 31818 rows (total: 31818)\n",
      "✅ [2025-03-13 20:16:03] Loaded 31818 rows (total: 63636)\n",
      "✅ [2025-03-13 20:16:12] Loaded 31818 rows (total: 95454)\n",
      "✅ [2025-03-13 20:16:13] Loaded 4546 rows (total: 100000)\n",
      "✅ [2025-03-13 20:16:13] Successfully loaded 100000 rows from BigQuery!\n"
     ]
    }
   ],
   "source": [
    "# 📌 Set Up BigQuery Connection\n",
    "PROJECT_ID = \"travel-insider-452211\"\n",
    "DATASET_NAME = \"travel_insider_dataset\"\n",
    "TABLE_NAME = \"filtered_flights\"\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/home/sebastian/code/JPYY-96/travel_insider/raw_data/travel-insider-452211-181bd2eba48e.json\"\n",
    "\n",
    "# 📌 Initialize BigQuery Client\n",
    "client = bigquery.Client()\n",
    "query = f\"SELECT * FROM `{PROJECT_ID}.{DATASET_NAME}.{TABLE_NAME}` ORDER BY RAND()  LIMIT 100000\"\n",
    "\n",
    "# 📌 Load Data in Chunks with Timer\n",
    "chunk_size = 1000000\n",
    "data_chunks = []\n",
    "start_time = time.time()\n",
    "\n",
    "print(f\"⏳ [{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] Loading data from BigQuery in chunks...\")\n",
    "query_job = client.query(query)\n",
    "result_iter = query_job.result(page_size=chunk_size)\n",
    "\n",
    "for page in result_iter.pages:\n",
    "    chunk_data = [dict(row) for row in page]\n",
    "    df_chunk = pd.DataFrame(chunk_data)\n",
    "    data_chunks.append(df_chunk)\n",
    "    print(f\"✅ [{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] Loaded {len(df_chunk)} rows (total: {sum(len(c) for c in data_chunks)})\")\n",
    "\n",
    "data_query = pd.concat(data_chunks, ignore_index=True)\n",
    "print(f\"✅ [{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] Successfully loaded {len(data_query)} rows from BigQuery!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📌 Convert Date Columns\n",
    "data_query[\"searchDate\"] = pd.to_datetime(data_query[\"searchDate\"])\n",
    "data_query[\"flightDate\"] = pd.to_datetime(data_query[\"flightDate\"])\n",
    "\n",
    "# 📌 Feature Engineering\n",
    "data_query[\"days_to_flight\"] = (data_query[\"flightDate\"] - data_query[\"searchDate\"]).dt.days\n",
    "data_query[\"day_of_week\"] = data_query[\"flightDate\"].dt.dayofweek\n",
    "data_query[\"is_weekend\"] = (data_query[\"day_of_week\"] >= 5).astype(int)\n",
    "data_query[\"is_holiday_season\"] = data_query[\"flightDate\"].dt.month.isin([6, 7, 12]).astype(int)\n",
    "data_query[\"days_to_flight_squared\"] = data_query[\"days_to_flight\"] ** 2\n",
    "data_query[\"flight_month\"] = data_query[\"flightDate\"].dt.month\n",
    "data_query[\"flight_year\"] = data_query[\"flightDate\"].dt.year\n",
    "data_query[\"search_month\"] = data_query[\"searchDate\"].dt.month\n",
    "data_query[\"search_day\"] = data_query[\"searchDate\"].dt.day\n",
    "data_query[\"days_to_flight_log\"] = np.log1p(data_query[\"days_to_flight\"])\n",
    "\n",
    "# Remove invalid rows\n",
    "data_query = data_query[data_query[\"days_to_flight\"] > 0]\n",
    "\n",
    "# 📌 One-Hot Encode Categorical Features (Airports & Airlines)\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "encoded_features = encoder.fit_transform(data_query[['startingAirport', 'destinationAirport', 'segmentsAirlineName']])\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out())\n",
    "\n",
    "# 📌 Ordinal Encoding for Cabin Class\n",
    "data_query['segmentsCabinCode'] = data_query['segmentsCabinCode'].fillna('Coach').str.strip().str.title()\n",
    "data_query = data_query[data_query[ \"segmentsCabinCode\"].str.strip().str.title() == \"Coach\"]\n",
    "data_query.drop(columns=[\"segmentsCabinCode\"], inplace=True)\n",
    "# 📌 Merge Encoded Data\n",
    "data_query = data_query.reset_index(drop=True)\n",
    "data_query = pd.concat([data_query, encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_cbed0_row9_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_cbed0\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_cbed0_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_cbed0_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_cbed0_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_cbed0_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_cbed0_row0_col1\" class=\"data row0 col1\" >123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cbed0_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_cbed0_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_cbed0_row1_col1\" class=\"data row1 col1\" >totalFare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cbed0_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_cbed0_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_cbed0_row2_col1\" class=\"data row2 col1\" >Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cbed0_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_cbed0_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_cbed0_row3_col1\" class=\"data row3 col1\" >(69780, 48)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cbed0_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_cbed0_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_cbed0_row4_col1\" class=\"data row4 col1\" >(69780, 48)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cbed0_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_cbed0_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_cbed0_row5_col1\" class=\"data row5 col1\" >(48846, 48)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cbed0_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_cbed0_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_cbed0_row6_col1\" class=\"data row6 col1\" >(20934, 48)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cbed0_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_cbed0_row7_col0\" class=\"data row7 col0\" >Numeric features</td>\n",
       "      <td id=\"T_cbed0_row7_col1\" class=\"data row7 col1\" >46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cbed0_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_cbed0_row8_col0\" class=\"data row8 col0\" >Categorical features</td>\n",
       "      <td id=\"T_cbed0_row8_col1\" class=\"data row8 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cbed0_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_cbed0_row9_col0\" class=\"data row9 col0\" >Preprocess</td>\n",
       "      <td id=\"T_cbed0_row9_col1\" class=\"data row9 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cbed0_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_cbed0_row10_col0\" class=\"data row10 col0\" >Imputation type</td>\n",
       "      <td id=\"T_cbed0_row10_col1\" class=\"data row10 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cbed0_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_cbed0_row11_col0\" class=\"data row11 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_cbed0_row11_col1\" class=\"data row11 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cbed0_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_cbed0_row12_col0\" class=\"data row12 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_cbed0_row12_col1\" class=\"data row12 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cbed0_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_cbed0_row13_col0\" class=\"data row13 col0\" >Maximum one-hot encoding</td>\n",
       "      <td id=\"T_cbed0_row13_col1\" class=\"data row13 col1\" >25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cbed0_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_cbed0_row14_col0\" class=\"data row14 col0\" >Encoding method</td>\n",
       "      <td id=\"T_cbed0_row14_col1\" class=\"data row14 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cbed0_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_cbed0_row15_col0\" class=\"data row15 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_cbed0_row15_col1\" class=\"data row15 col1\" >KFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cbed0_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_cbed0_row16_col0\" class=\"data row16 col0\" >Fold Number</td>\n",
       "      <td id=\"T_cbed0_row16_col1\" class=\"data row16 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cbed0_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_cbed0_row17_col0\" class=\"data row17 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_cbed0_row17_col1\" class=\"data row17 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cbed0_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_cbed0_row18_col0\" class=\"data row18 col0\" >Use GPU</td>\n",
       "      <td id=\"T_cbed0_row18_col1\" class=\"data row18 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cbed0_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_cbed0_row19_col0\" class=\"data row19 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_cbed0_row19_col1\" class=\"data row19 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cbed0_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_cbed0_row20_col0\" class=\"data row20 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_cbed0_row20_col1\" class=\"data row20 col1\" >reg-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cbed0_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_cbed0_row21_col0\" class=\"data row21 col0\" >USI</td>\n",
       "      <td id=\"T_cbed0_row21_col1\" class=\"data row21 col1\" >2b90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f62265581c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Initiated</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>20:16:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Status</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>Fitting 10 Folds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Estimator</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>Random Forest Regressor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                       \n",
       "                                                                       \n",
       "Initiated  . . . . . . . . . . . . . . . . . .                 20:16:23\n",
       "Status     . . . . . . . . . . . . . . . . . .         Fitting 10 Folds\n",
       "Estimator  . . . . . . . . . . . . . . . . . .  Random Forest Regressor"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_48fff th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_48fff_row0_col0, #T_48fff_row0_col1, #T_48fff_row0_col2, #T_48fff_row0_col3, #T_48fff_row0_col4, #T_48fff_row0_col5, #T_48fff_row0_col6, #T_48fff_row0_col7, #T_48fff_row1_col0, #T_48fff_row1_col1, #T_48fff_row1_col2, #T_48fff_row1_col3, #T_48fff_row1_col4, #T_48fff_row1_col5, #T_48fff_row1_col6, #T_48fff_row1_col7, #T_48fff_row2_col0, #T_48fff_row2_col1, #T_48fff_row2_col2, #T_48fff_row2_col3, #T_48fff_row2_col4, #T_48fff_row2_col5, #T_48fff_row2_col6, #T_48fff_row2_col7, #T_48fff_row3_col0, #T_48fff_row3_col1, #T_48fff_row3_col2, #T_48fff_row3_col3, #T_48fff_row3_col4, #T_48fff_row3_col5, #T_48fff_row3_col6, #T_48fff_row3_col7, #T_48fff_row4_col0, #T_48fff_row4_col1, #T_48fff_row4_col2, #T_48fff_row4_col3, #T_48fff_row4_col4, #T_48fff_row4_col5, #T_48fff_row4_col6, #T_48fff_row4_col7, #T_48fff_row5_col0, #T_48fff_row5_col1, #T_48fff_row5_col2, #T_48fff_row5_col3, #T_48fff_row5_col4, #T_48fff_row5_col5, #T_48fff_row5_col6, #T_48fff_row5_col7, #T_48fff_row6_col0, #T_48fff_row6_col1, #T_48fff_row6_col2, #T_48fff_row6_col3, #T_48fff_row6_col4, #T_48fff_row6_col5, #T_48fff_row6_col6, #T_48fff_row6_col7, #T_48fff_row7_col0, #T_48fff_row7_col1, #T_48fff_row7_col2, #T_48fff_row7_col3, #T_48fff_row7_col4, #T_48fff_row7_col5, #T_48fff_row7_col6, #T_48fff_row7_col7, #T_48fff_row8_col0, #T_48fff_row8_col1, #T_48fff_row8_col2, #T_48fff_row8_col3, #T_48fff_row8_col4, #T_48fff_row8_col5, #T_48fff_row8_col6, #T_48fff_row8_col7, #T_48fff_row9_col0, #T_48fff_row9_col1, #T_48fff_row9_col2, #T_48fff_row9_col3, #T_48fff_row9_col4, #T_48fff_row9_col5, #T_48fff_row9_col6, #T_48fff_row9_col7, #T_48fff_row10_col0, #T_48fff_row10_col1, #T_48fff_row10_col2, #T_48fff_row10_col3, #T_48fff_row10_col4, #T_48fff_row10_col5, #T_48fff_row10_col6, #T_48fff_row10_col7, #T_48fff_row11_col0, #T_48fff_row11_col1, #T_48fff_row11_col2, #T_48fff_row11_col3, #T_48fff_row11_col4, #T_48fff_row11_col5, #T_48fff_row11_col6, #T_48fff_row11_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_48fff\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_48fff_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_48fff_level0_col1\" class=\"col_heading level0 col1\" >MAE</th>\n",
       "      <th id=\"T_48fff_level0_col2\" class=\"col_heading level0 col2\" >MSE</th>\n",
       "      <th id=\"T_48fff_level0_col3\" class=\"col_heading level0 col3\" >RMSE</th>\n",
       "      <th id=\"T_48fff_level0_col4\" class=\"col_heading level0 col4\" >R2</th>\n",
       "      <th id=\"T_48fff_level0_col5\" class=\"col_heading level0 col5\" >RMSLE</th>\n",
       "      <th id=\"T_48fff_level0_col6\" class=\"col_heading level0 col6\" >MAPE</th>\n",
       "      <th id=\"T_48fff_level0_col7\" class=\"col_heading level0 col7\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_48fff_level0_row0\" class=\"row_heading level0 row0\" >br</th>\n",
       "      <td id=\"T_48fff_row0_col0\" class=\"data row0 col0\" >Bayesian Ridge</td>\n",
       "      <td id=\"T_48fff_row0_col1\" class=\"data row0 col1\" >104.2967</td>\n",
       "      <td id=\"T_48fff_row0_col2\" class=\"data row0 col2\" >19990.6108</td>\n",
       "      <td id=\"T_48fff_row0_col3\" class=\"data row0 col3\" >141.3594</td>\n",
       "      <td id=\"T_48fff_row0_col4\" class=\"data row0 col4\" >0.0778</td>\n",
       "      <td id=\"T_48fff_row0_col5\" class=\"data row0 col5\" >0.5152</td>\n",
       "      <td id=\"T_48fff_row0_col6\" class=\"data row0 col6\" >0.5132</td>\n",
       "      <td id=\"T_48fff_row0_col7\" class=\"data row0 col7\" >0.0800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_48fff_level0_row1\" class=\"row_heading level0 row1\" >lr</th>\n",
       "      <td id=\"T_48fff_row1_col0\" class=\"data row1 col0\" >Linear Regression</td>\n",
       "      <td id=\"T_48fff_row1_col1\" class=\"data row1 col1\" >104.3147</td>\n",
       "      <td id=\"T_48fff_row1_col2\" class=\"data row1 col2\" >19992.9997</td>\n",
       "      <td id=\"T_48fff_row1_col3\" class=\"data row1 col3\" >141.3678</td>\n",
       "      <td id=\"T_48fff_row1_col4\" class=\"data row1 col4\" >0.0777</td>\n",
       "      <td id=\"T_48fff_row1_col5\" class=\"data row1 col5\" >0.5152</td>\n",
       "      <td id=\"T_48fff_row1_col6\" class=\"data row1 col6\" >0.5132</td>\n",
       "      <td id=\"T_48fff_row1_col7\" class=\"data row1 col7\" >0.3410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_48fff_level0_row2\" class=\"row_heading level0 row2\" >ridge</th>\n",
       "      <td id=\"T_48fff_row2_col0\" class=\"data row2 col0\" >Ridge Regression</td>\n",
       "      <td id=\"T_48fff_row2_col1\" class=\"data row2 col1\" >104.3144</td>\n",
       "      <td id=\"T_48fff_row2_col2\" class=\"data row2 col2\" >19992.9743</td>\n",
       "      <td id=\"T_48fff_row2_col3\" class=\"data row2 col3\" >141.3677</td>\n",
       "      <td id=\"T_48fff_row2_col4\" class=\"data row2 col4\" >0.0777</td>\n",
       "      <td id=\"T_48fff_row2_col5\" class=\"data row2 col5\" >0.5152</td>\n",
       "      <td id=\"T_48fff_row2_col6\" class=\"data row2 col6\" >0.5132</td>\n",
       "      <td id=\"T_48fff_row2_col7\" class=\"data row2 col7\" >0.1090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_48fff_level0_row3\" class=\"row_heading level0 row3\" >lasso</th>\n",
       "      <td id=\"T_48fff_row3_col0\" class=\"data row3 col0\" >Lasso Regression</td>\n",
       "      <td id=\"T_48fff_row3_col1\" class=\"data row3 col1\" >104.3171</td>\n",
       "      <td id=\"T_48fff_row3_col2\" class=\"data row3 col2\" >20006.6998</td>\n",
       "      <td id=\"T_48fff_row3_col3\" class=\"data row3 col3\" >141.4168</td>\n",
       "      <td id=\"T_48fff_row3_col4\" class=\"data row3 col4\" >0.0770</td>\n",
       "      <td id=\"T_48fff_row3_col5\" class=\"data row3 col5\" >0.5156</td>\n",
       "      <td id=\"T_48fff_row3_col6\" class=\"data row3 col6\" >0.5139</td>\n",
       "      <td id=\"T_48fff_row3_col7\" class=\"data row3 col7\" >0.8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_48fff_level0_row4\" class=\"row_heading level0 row4\" >llar</th>\n",
       "      <td id=\"T_48fff_row4_col0\" class=\"data row4 col0\" >Lasso Least Angle Regression</td>\n",
       "      <td id=\"T_48fff_row4_col1\" class=\"data row4 col1\" >104.3170</td>\n",
       "      <td id=\"T_48fff_row4_col2\" class=\"data row4 col2\" >20006.6904</td>\n",
       "      <td id=\"T_48fff_row4_col3\" class=\"data row4 col3\" >141.4167</td>\n",
       "      <td id=\"T_48fff_row4_col4\" class=\"data row4 col4\" >0.0770</td>\n",
       "      <td id=\"T_48fff_row4_col5\" class=\"data row4 col5\" >0.5156</td>\n",
       "      <td id=\"T_48fff_row4_col6\" class=\"data row4 col6\" >0.5139</td>\n",
       "      <td id=\"T_48fff_row4_col7\" class=\"data row4 col7\" >0.0410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_48fff_level0_row5\" class=\"row_heading level0 row5\" >en</th>\n",
       "      <td id=\"T_48fff_row5_col0\" class=\"data row5 col0\" >Elastic Net</td>\n",
       "      <td id=\"T_48fff_row5_col1\" class=\"data row5 col1\" >104.5531</td>\n",
       "      <td id=\"T_48fff_row5_col2\" class=\"data row5 col2\" >20144.8132</td>\n",
       "      <td id=\"T_48fff_row5_col3\" class=\"data row5 col3\" >141.9056</td>\n",
       "      <td id=\"T_48fff_row5_col4\" class=\"data row5 col4\" >0.0706</td>\n",
       "      <td id=\"T_48fff_row5_col5\" class=\"data row5 col5\" >0.5178</td>\n",
       "      <td id=\"T_48fff_row5_col6\" class=\"data row5 col6\" >0.5171</td>\n",
       "      <td id=\"T_48fff_row5_col7\" class=\"data row5 col7\" >0.1130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_48fff_level0_row6\" class=\"row_heading level0 row6\" >omp</th>\n",
       "      <td id=\"T_48fff_row6_col0\" class=\"data row6 col0\" >Orthogonal Matching Pursuit</td>\n",
       "      <td id=\"T_48fff_row6_col1\" class=\"data row6 col1\" >104.9536</td>\n",
       "      <td id=\"T_48fff_row6_col2\" class=\"data row6 col2\" >20303.4803</td>\n",
       "      <td id=\"T_48fff_row6_col3\" class=\"data row6 col3\" >142.4644</td>\n",
       "      <td id=\"T_48fff_row6_col4\" class=\"data row6 col4\" >0.0633</td>\n",
       "      <td id=\"T_48fff_row6_col5\" class=\"data row6 col5\" >0.5208</td>\n",
       "      <td id=\"T_48fff_row6_col6\" class=\"data row6 col6\" >0.5205</td>\n",
       "      <td id=\"T_48fff_row6_col7\" class=\"data row6 col7\" >0.0410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_48fff_level0_row7\" class=\"row_heading level0 row7\" >huber</th>\n",
       "      <td id=\"T_48fff_row7_col0\" class=\"data row7 col0\" >Huber Regressor</td>\n",
       "      <td id=\"T_48fff_row7_col1\" class=\"data row7 col1\" >101.7411</td>\n",
       "      <td id=\"T_48fff_row7_col2\" class=\"data row7 col2\" >20760.1261</td>\n",
       "      <td id=\"T_48fff_row7_col3\" class=\"data row7 col3\" >144.0566</td>\n",
       "      <td id=\"T_48fff_row7_col4\" class=\"data row7 col4\" >0.0422</td>\n",
       "      <td id=\"T_48fff_row7_col5\" class=\"data row7 col5\" >0.5037</td>\n",
       "      <td id=\"T_48fff_row7_col6\" class=\"data row7 col6\" >0.4589</td>\n",
       "      <td id=\"T_48fff_row7_col7\" class=\"data row7 col7\" >0.2950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_48fff_level0_row8\" class=\"row_heading level0 row8\" >knn</th>\n",
       "      <td id=\"T_48fff_row8_col0\" class=\"data row8 col0\" >K Neighbors Regressor</td>\n",
       "      <td id=\"T_48fff_row8_col1\" class=\"data row8 col1\" >110.5756</td>\n",
       "      <td id=\"T_48fff_row8_col2\" class=\"data row8 col2\" >22908.7318</td>\n",
       "      <td id=\"T_48fff_row8_col3\" class=\"data row8 col3\" >151.3336</td>\n",
       "      <td id=\"T_48fff_row8_col4\" class=\"data row8 col4\" >-0.0571</td>\n",
       "      <td id=\"T_48fff_row8_col5\" class=\"data row8 col5\" >0.5422</td>\n",
       "      <td id=\"T_48fff_row8_col6\" class=\"data row8 col6\" >0.5234</td>\n",
       "      <td id=\"T_48fff_row8_col7\" class=\"data row8 col7\" >0.2930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_48fff_level0_row9\" class=\"row_heading level0 row9\" >par</th>\n",
       "      <td id=\"T_48fff_row9_col0\" class=\"data row9 col0\" >Passive Aggressive Regressor</td>\n",
       "      <td id=\"T_48fff_row9_col1\" class=\"data row9 col1\" >128.1805</td>\n",
       "      <td id=\"T_48fff_row9_col2\" class=\"data row9 col2\" >31467.3316</td>\n",
       "      <td id=\"T_48fff_row9_col3\" class=\"data row9 col3\" >176.1132</td>\n",
       "      <td id=\"T_48fff_row9_col4\" class=\"data row9 col4\" >-0.4541</td>\n",
       "      <td id=\"T_48fff_row9_col5\" class=\"data row9 col5\" >0.6986</td>\n",
       "      <td id=\"T_48fff_row9_col6\" class=\"data row9 col6\" >0.5331</td>\n",
       "      <td id=\"T_48fff_row9_col7\" class=\"data row9 col7\" >0.0800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_48fff_level0_row10\" class=\"row_heading level0 row10\" >dt</th>\n",
       "      <td id=\"T_48fff_row10_col0\" class=\"data row10 col0\" >Decision Tree Regressor</td>\n",
       "      <td id=\"T_48fff_row10_col1\" class=\"data row10 col1\" >141.3979</td>\n",
       "      <td id=\"T_48fff_row10_col2\" class=\"data row10 col2\" >39541.4862</td>\n",
       "      <td id=\"T_48fff_row10_col3\" class=\"data row10 col3\" >198.8229</td>\n",
       "      <td id=\"T_48fff_row10_col4\" class=\"data row10 col4\" >-0.8251</td>\n",
       "      <td id=\"T_48fff_row10_col5\" class=\"data row10 col5\" >0.6885</td>\n",
       "      <td id=\"T_48fff_row10_col6\" class=\"data row10 col6\" >0.6475</td>\n",
       "      <td id=\"T_48fff_row10_col7\" class=\"data row10 col7\" >0.0850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_48fff_level0_row11\" class=\"row_heading level0 row11\" >lar</th>\n",
       "      <td id=\"T_48fff_row11_col0\" class=\"data row11 col0\" >Least Angle Regression</td>\n",
       "      <td id=\"T_48fff_row11_col1\" class=\"data row11 col1\" >221470.6813</td>\n",
       "      <td id=\"T_48fff_row11_col2\" class=\"data row11 col2\" >393223270515.2809</td>\n",
       "      <td id=\"T_48fff_row11_col3\" class=\"data row11 col3\" >296576.5504</td>\n",
       "      <td id=\"T_48fff_row11_col4\" class=\"data row11 col4\" >-18375351.9938</td>\n",
       "      <td id=\"T_48fff_row11_col5\" class=\"data row11 col5\" >3.0152</td>\n",
       "      <td id=\"T_48fff_row11_col6\" class=\"data row11 col6\" >1127.7196</td>\n",
       "      <td id=\"T_48fff_row11_col7\" class=\"data row11 col7\" >0.0430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f6224799240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53b947d66a5d40b48f0e5223d798e78a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# :drawing_pin: Prepare Data\n",
    "# Assuming `data_query` is your dataset and you already have `encoded_df`\n",
    "X = data_query[['days_to_flight', 'days_to_flight_squared', 'day_of_week', 'is_weekend', 'is_holiday_season',\n",
    "                'flight_month', 'flight_year', 'search_month', 'search_day', 'days_to_flight_log',\n",
    "                'seatsRemaining', 'isRefundable'] + list(encoded_df.columns)]\n",
    "y = data_query['totalFare']\n",
    "# :drawing_pin: Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "# Combine the data into a DataFrame for PyCaret\n",
    "data = X_train.copy()\n",
    "data['totalFare'] = y_train\n",
    "data = data.dropna(subset=['totalFare'])  # ✅ Drop rows where `totalFare` is NaN\n",
    "\n",
    "\n",
    "# :drawing_pin: Initialize PyCaret Regression Environment\n",
    "regression_setup = setup(data, target='totalFare', session_id=123, fold_shuffle=True)\n",
    "# :drawing_pin: Compare Multiple Models\n",
    "model_comparison = compare_models()\n",
    "# :drawing_pin: Display the model comparison table\n",
    "# This will display a dataframe with the results of all models evaluated\n",
    "print(model_comparison)\n",
    "# :drawing_pin: Evaluate the Best Model\n",
    "best_model = model_comparison\n",
    "evaluate_model(best_model)\n",
    "# :drawing_pin: Tune the Best Model (Optional)\n",
    "tuned_model = tune_model(best_model)\n",
    "# :drawing_pin: Finalize and Save the Model\n",
    "final_model = finalize_model(tuned_model)\n",
    "#save_model(final_model, 'final_regression_model')\n",
    "# :drawing_pin: Predict on Test Set using the Finalized Model\n",
    "y_pred_final = predict_model(final_model, data=X_test)\n",
    "# :drawing_pin: Evaluate the Final Model\n",
    "mae_final = mean_absolute_error(y_test, y_pred_final['Label'])\n",
    "mape_final = (mae_final / y_test.mean()) * 100\n",
    "print(f\"\\n:bar_chart: Final Model MAE: ${mae_final:.2f}, MAPE: {mape_final:.2f}%\")\n",
    "# :drawing_pin: If you'd like to blend models (like XGBoost and LightGBM), PyCaret can handle ensembling.\n",
    "# Create an ensemble of the top models (XGBoost, LightGBM, etc.)\n",
    "blended_model = blend_models([best_model, tuned_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052006 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 328\n",
      "[LightGBM] [Info] Number of data points in the train set: 700000, number of used features: 46\n",
      "[LightGBM] [Info] Start training from score 265.116839\n"
     ]
    }
   ],
   "source": [
    "# 📌 Select Features\n",
    "X = data_query[['days_to_flight', 'days_to_flight_squared', 'day_of_week', 'is_weekend', 'is_holiday_season',\n",
    "                'flight_month', 'flight_year', 'search_month', 'search_day', 'days_to_flight_log',\n",
    "                'seatsRemaining', 'isRefundable', 'cabin_class_encoded'] + list(encoded_df.columns)]\n",
    "y = data_query['totalFare']\n",
    "\n",
    "# 📌 Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 📌 Train XGBoost Model\n",
    "xgb_model = XGBRegressor(\n",
    "    n_estimators=500, learning_rate=0.05, max_depth=8,\n",
    "    subsample=0.8, colsample_bytree=0.8, random_state=42\n",
    ")\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# 📌 Train LightGBM Model\n",
    "lgbm_model = LGBMRegressor(\n",
    "    n_estimators=700, learning_rate=0.03, max_depth=10,\n",
    "    subsample=0.8, colsample_bytree=0.8, random_state=42\n",
    ")\n",
    "lgbm_model.fit(X_train, y_train)\n",
    "\n",
    "# 📌 Make Predictions\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "y_pred_lgbm = lgbm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 XGBoost MAE: $54.17, MAPE: 20.44%\n",
      "📊 LightGBM MAE: $61.12, MAPE: 23.07%\n",
      "\n",
      "📊 Blended Model MAE: $55.61, MAPE: 20.99%\n"
     ]
    }
   ],
   "source": [
    "# 📌 Evaluate Models\n",
    "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
    "mape_xgb = (mae_xgb / y_test.mean()) * 100\n",
    "\n",
    "mae_lgbm = mean_absolute_error(y_test, y_pred_lgbm)\n",
    "mape_lgbm = (mae_lgbm / y_test.mean()) * 100\n",
    "\n",
    "print(f\"\\n📊 XGBoost MAE: ${mae_xgb:.2f}, MAPE: {mape_xgb:.2f}%\")\n",
    "print(f\"📊 LightGBM MAE: ${mae_lgbm:.2f}, MAPE: {mape_lgbm:.2f}%\")\n",
    "\n",
    "# 📌 Combine XGBoost and LightGBM Predictions (Weighted Average)\n",
    "y_pred_blended = (0.7 * y_pred_xgb) + (0.3 * y_pred_lgbm)\n",
    "\n",
    "# 📌 Evaluate Blended Model\n",
    "mae_blended = mean_absolute_error(y_test, y_pred_blended)\n",
    "mape_blended = (mae_blended / y_test.mean()) * 100\n",
    "print(f\"\\n📊 Blended Model MAE: ${mae_blended:.2f}, MAPE: {mape_blended:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📅 Best date to book for any flight (May 1st flight): 2025-05-24\n",
      "\n",
      "⏳ Total script execution time: 384.98 seconds\n"
     ]
    }
   ],
   "source": [
    "# 📌 Find Best Booking Date for Any Flight\n",
    "flight_date = datetime(2025, 5, 30)\n",
    "search_dates = [flight_date - timedelta(days=i) for i in range(1, 61)]\n",
    "\n",
    "# 📌 Create DataFrame for Predictions with All Required Features\n",
    "search_df = pd.DataFrame({\n",
    "    'days_to_flight': [(flight_date - d).days for d in search_dates],\n",
    "    'days_to_flight_squared': [(flight_date - d).days ** 2 for d in search_dates],\n",
    "    'day_of_week': [d.weekday() for d in search_dates],\n",
    "    'is_weekend': [1 if d.weekday() >= 5 else 0 for d in search_dates],\n",
    "    'is_holiday_season': [1 if d.month in [6, 7, 12] else 0 for d in search_dates],\n",
    "    'flight_month': [d.month for d in search_dates],  # ✅ Added\n",
    "    'flight_year': [d.year for d in search_dates],  # ✅ Added\n",
    "    'search_month': [flight_date.month] * len(search_dates),  # ✅ Added\n",
    "    'search_day': [flight_date.day] * len(search_dates),  # ✅ Added\n",
    "    'days_to_flight_log': [np.log1p((flight_date - d).days) for d in search_dates],  # ✅ Added\n",
    "\n",
    "})\n",
    "\n",
    "# 📌 Add Encoded Features (Default Values)\n",
    "for col in encoded_df.columns:\n",
    "    search_df[col] = 0\n",
    "\n",
    "# 📌 Reorder Columns to Match `X_train`\n",
    "search_df = search_df[X_train.columns]\n",
    "# 📌 Predict Prices for Different Booking Dates\n",
    "predicted_fares = xgb_model.predict(search_df)\n",
    "\n",
    "# 📌 Find Best Date to Book\n",
    "best_search_date = search_dates[np.argmin(predicted_fares)]\n",
    "print(f\"\\n📅 Best date to book for any flight (May 1st flight): {best_search_date.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "# 📌 Print Total Execution Time\n",
    "print(f\"\\n⏳ Total script execution time: {time.time() - start_time:.2f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "travel_insider",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
